{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9468a857",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <img src=\"SAGE_logo.jpeg\" alt=\"descripciÃ³n\" width=\"150\" style=\"margin-right: 10px; vertical-align: middle;\">\n",
    "    <h1>NSF National Data Platform (NDP)</h1>\n",
    "</div>\n",
    "\n",
    "<h3 style=\"text-align: center; margin-top: 0;\">Streaming Data from SAGE Pilot</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a5cc9",
   "metadata": {},
   "source": [
    "**Contact:** Scientific and Computing Imaging Institute, University of Utah ([ivan.rodero@utah.edu](mailto:ivan.rodero@utah.edu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3e53f8-4dea-4c6f-8dfb-c76a1cffe3b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <img src=\"https://new.nsf.gov/themes/custom/nsf_theme/components/images/logo/logo-desktop.svg\" alt=\"NSF Logo\" width=\"120\" style=\"margin-right: 10px; vertical-align: middle;\">\n",
    "    <span style=\"font-size: 10px; margin-top:10px;\">The National Data Platform was funded by NSF 2333609 under CI, CISE Research Resources programs. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the funders.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f81c0d",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "- `import asyncio`: Used for writing concurrent code using the async/await syntax.\n",
    "- `import json`: This library is used for parsing JSON data.\n",
    "- `import os`: Provides a way of using operating system dependent functionality like reading or writing to a file.\n",
    "- `import webbrowser`: Allows displaying web-based documents to users.\n",
    "- `from datetime import datetime`: For handling date and time information.\n",
    "- `from IPython.display import clear_output, display`: Used for displaying output in Jupyter Notebooks and clearing the output respectively.\n",
    "- `import ipywidgets as widgets`: Provides interactive HTML widgets for Jupyter notebooks.\n",
    "- `from aiokafka import AIOKafkaConsumer`: Asynchronous Kafka client that consumes messages from a Kafka topic.\n",
    "- `from plotly.graph_objs import FigureWidget, Scatter`: For creating interactive visualizations using Plotly within Jupyter Notebooks.\n",
    "- `from plotly.subplots import make_subplots`: Utility to create figures with multiple subplots.\n",
    "- `import plotly.graph_objects as go`: Contains graph objects for all types of visualizations.\n",
    "- `import numpy as np`: Fundamental package for scientific computing with Python.\n",
    "- `import nest_asyncio`: Apply a patch to the asyncio module to allow nested use of asyncio.run and loop.run_until_complete.\n",
    "- `from ai_forecast import IncrementalModel, parse_timestamp`: Imports custom classes and functions for forecasting and timestamp parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0252430d-d011-4028-8aed-f1f0e7335016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import webbrowser\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntText, HBox, Label\n",
    "from aiokafka import AIOKafkaConsumer\n",
    "from plotly.graph_objs import FigureWidget, Scatter\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from ai_forecast import IncrementalModel, parse_timestamp\n",
    "import requests\n",
    "import pandas as pd\n",
    "from basic_functions import get_and_display_consumer_data, stream_and_visualize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47c72ef-c3ac-496d-b7ea-b08529f26e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_HOST = \"155.101.6.194\"\n",
    "KAFKA_PORT = \"9092\"\n",
    "consumers = [\"wind\", \"temperature\", \"humidity\", \"pressure\", \"air_quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d0b706-a00e-44d1-b322-d51f2b14b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the active consumers, we can make a call to the Master API endpoint that retrieves and displays them:\n",
    "#consumer_ids = get_and_display_consumer_data('http://master_api:8000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c5ef6-b2be-4290-b7f6-7ee52c6ab958",
   "metadata": {},
   "source": [
    "### Real-Time Data Streaming and Visualization\n",
    "\n",
    "The `stream_and_visualize_data` function is at the heart of our real-time data analysis and visualization tool. It connects to a Kafka topic as a consumer using a given `consumer_id` and streams data in real time. The function then processes and visualizes this data dynamically, providing insights into trends as they occur.\n",
    "\n",
    "Key components of this function include:\n",
    "- **Kafka Consumer Initialization**: Establishes a connection to a Kafka topic to consume messages.\n",
    "- **Data Processing**: Upon receiving data, it parses the JSON payload, extracts relevant information, and updates the data model.\n",
    "- **Model Training and Prediction**: Utilizes an incremental model to train on the newly arrived data and makes future predictions based on the model.\n",
    "- **Dynamic Visualization**: Leverages Plotly to plot real-time data and predictions. The visualization includes both historical data and the latest data points to show trends over time.\n",
    "- **Saving Option**: Optionally, the visualized data can be saved as an HTML file for offline viewing and shared with others.\n",
    "\n",
    "This approach enables real-time monitoring and forecasting, making it invaluable for applications requiring up-to-the-minute data analysis, such as environmental monitoring, financial market tracking, or IoT device management.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b9881-7701-43b8-a141-f6b3f1ced363",
   "metadata": {},
   "source": [
    "### Visualizing Real-Time Data for a Selected Consumer\n",
    "\n",
    "After retrieving and displaying the active consumers, we can focus on a specific consumer to visualize their data in real time. By selecting a consumer ID from the previously obtained array of consumer IDs, we can tailor our data visualization to show trends and predictions related to that particular consumer's data stream.\n",
    "\n",
    "The code snippet below demonstrates how to select the third consumer from our list (noting that Python uses zero-based indexing) and visualize their real-time data along with future predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298b69a3-4b78-41a2-a65b-a7d3ae76daff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b108656a29d4073ad05a0556d3d5523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'name': 'Real Data - Historical',\n",
       "              'type': 'scatter',\n",
       "              'uid': '9927abe5-ace9-45ea-963e-ee7f603c3cf8'},\n",
       "             {'mode': 'lines+markers',\n",
       "              'name': 'Real Data - Latest',\n",
       "              'type': 'scatter',\n",
       "              'uid': '48e80745-0099-49d9-9893-0eea753b6a1a'},\n",
       "             {'line': {'dash': 'dot'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Predictions - Historical',\n",
       "              'type': 'scatter',\n",
       "              'uid': '38acecd6-e35d-4473-9616-038d5deb87d1'},\n",
       "             {'line': {'dash': 'dot'},\n",
       "              'mode': 'lines+markers',\n",
       "              'name': 'Predictions - Latest',\n",
       "              'type': 'scatter',\n",
       "              'uid': '9d80f4ed-4cbe-4362-8d8c-6a623c8eecf8'}],\n",
       "    'layout': {'autosize': True,\n",
       "               'height': 600,\n",
       "               'template': '...',\n",
       "               'title': {'text': 'Real-Time Data and Predictions for consumer wind'},\n",
       "               'width': 1600,\n",
       "               'xaxis': {'tickformat': '%m/%d/%Y-%H:%M:%S', 'title': {'text': 'Timestamp'}},\n",
       "               'yaxis': {'title': {'text': 'Value'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/ai_forecast.py:30: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "/home/jovyan/work/ai_forecast.py:61: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m consumer_id \u001b[38;5;241m=\u001b[39m consumers[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m stream_and_visualize_data(KAFKA_HOST, KAFKA_PORT, consumer_id, predictions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, timestamp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/work/basic_functions.py:137\u001b[0m, in \u001b[0;36mstream_and_visualize_data\u001b[0;34m(kafka_host, kafka_port, consumer_id, predictions, timestamp, save)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 fig\u001b[38;5;241m.\u001b[39mwrite_html(filepath, auto_open\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m                 webbrowser\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filepath, new\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)  \u001b[38;5;66;03m# Control the update rate\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m consumer\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/tasks.py:649\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    645\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[1;32m    646\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[1;32m    647\u001b[0m                     future, result)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    651\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/asyncio/futures.py:287\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "consumer_id = consumers[0]\n",
    "await stream_and_visualize_data(KAFKA_HOST, KAFKA_PORT, consumer_id, predictions=20, timestamp=False, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb900a98-7e11-48a4-9b25-3511e088426a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
