{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ca83c4-070a-458d-940f-4f886b80bcfb",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 40px; margin-top: 0;\">\n",
    "    <div style=\"flex: 0 0 auto; margin-left: 0; margin-bottom: 0;margin-top: 0;\">\n",
    "        <img src=\"../pics/NationalDataPlatform_logo.png\" alt=\"WiFire Logo\" style=\"width: 179px; margin-bottom: 0px;\">\n",
    "    </div>    \n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 0;\">\n",
    "        <img src=\"../pics/logo_UCSD.png\" alt=\"UCSD Logo\" style=\"width: 179px; margin-bottom: 0px; margin-top: 20px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 20px;\">\n",
    "        <img src=\"../pics/sdsclogo-plusname-horiz-red.jpg\" alt=\"San Diego Supercomputer Center Logo\" width=\"300\"/>\n",
    "    </div>\n",
    "</div>\n",
    "<h1 style=\"text-align: center; font-size: 24px; margin-top: 0;\">NSF National Data Platform (NDP)</h1>\n",
    "<h3 style=\"text-align: center; font-size: 18px; margin-top: 10px;\">LLM as a Service Tutorial</h3>\n",
    "<div style=\"margin: 20px 0;\">\n",
    "    <p align=\"justify\"> Large Language Models are a powerful AI tool with multiple applications in both research and education, given their capacity to process big amounts of information to generate human-like language.</p>\n",
    "    <p align=\"justify\"> Understanding today's relevance of LLM's, the National Data Platform (NDP) has developed an LLM service to contribute to the research and education goals of its users.</p>\n",
    "    <p align=\"justify\"> In this guide, we are covering the use of an LLM as an NDP service. The main purpose of this demo is to showcase how this service works by submitting a series of sample queries, as well as comparing the performance when adding new documentation to a model. The main goal is to allow the user to identify the potential use cases of this service.</p>\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "    <div style=\"text-align: right; padding: 5px;\">\n",
    "        <p style=\"text-align: right;\"><strong>Contact:</strong><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfzjlc0Sw2fTFTKArOZ0ffKNdVcPivf218kLXkBKfobGPbDMw/viewform\"> NDP Issue Reporting Form </a></p>\n",
    "    </div>\n",
    "</cente\n",
    "\n",
    "\n",
    "<div style=\"display: flex; align-items: center; justify-content: flex-start; margin-top: 20px; border-top: 1px solid #ccc; padding-top: 20px;\">\n",
    "    <img src=\"https://new.nsf.gov/themes/custom/nsf_theme/components/images/logo/logo-desktop.svg\" alt=\"NSF Logo\" style=\"width: 120px; margin-right: 10px;\">\n",
    "    <p style=\"font-size: 12px;\">The National Data Platform was funded by NSF 2333609 under CI, CISE Research Resources programs. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the funders.</p>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab8610-5676-468a-b2a8-01392a229cdc",
   "metadata": {},
   "source": [
    "### What is an LLM?\n",
    "\n",
    "An LLM, or Large Language Model, is a type of artificial intelligence designed to understand and generate human-like text based on the data it's been trained on. By adding a vast amount of text from different sources and context's (web, books, papers, among others) LLM's are capable to identify the patterns of the human language under different contexts and provide responses to complex questions. \n",
    "\n",
    "LLM's posses a huge potential in both research and education, given their capability to quickly process and summarize a vast amount of information. LLM's can bee seen as a powerful tool to accelerate learning, facilitate the sharing of knowledge, process and generate big amounts of data, generate new hypothesis questions, among other uses.\n",
    "\n",
    "### ClimateGPT\n",
    "\n",
    "For this demo, we are using the [ClimateGPT](https://climategpt.ai/) model. Climate GPT was developed by team of researchers at RWTH Aachen University, in collaboration with Erasmus AI and others, for interdisciplinary research focused on climate change. They constructed 7B models from the ground up, utilizing a scientifically-oriented dataset of 300 billion tokens.  \n",
    "\n",
    "The model was made publicly available through [HuggingFace](https://huggingface.co/eci-io/climategpt-70b) in January 2024. It comes in well-maintained 7B, 13B, and 70B versions, built upon the Llama 2 architecture and leveraging a dataset of 4.2 billion tokens.\n",
    "\n",
    "### Hands on\n",
    "\n",
    "We will start using LLM as a service. First, we will make some questions to the vanilla ClimateGPT to see its overall performance. Then, we will extend the chorpus of the model by adding a new document. We expect the model to be able to answer questions based on the new document.\n",
    "\n",
    "### A. Set Up\n",
    "\n",
    "We start by importing relevant libraries and functions. Also, we call the model and connect to the server's API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0191bc9-8149-4316-8617-e8e4fda0b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "MODEL = 'eci-io/climategpt-7b' # We specify the model tu use\n",
    "os.environ['OPENAI_API_BASE'] = 'http://localhost:8000/v1'\n",
    "os.environ['OPENAI_API_KEY'] = 'EMPTY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ff451-27e7-41ac-901d-d6bfcfc3f9b2",
   "metadata": {},
   "source": [
    "### Test that LLM API is up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889395f9-a7b1-413e-b67b-8f494abd5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl  -X 'GET' 'http://localhost:8000/v1/models' -H 'accept: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb480fdb-4e1d-44cc-a414-223d22f38e03",
   "metadata": {},
   "source": [
    "### The conversation code\n",
    "\n",
    "In the following cells, we define a series of functions to interact with ClimateGPT in a form of a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066f108-e7fd-4d29-b080-e8b3b654aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answer(question, answer):\n",
    "    with open('output.txt', 'a') as file:\n",
    "        file.write(question+'\\n')\n",
    "        file.write(answer+'\\n\\n')\n",
    "    \n",
    "\n",
    "def query(question, chorpus):\n",
    "    url = \"http://localhost:8000/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "    }\n",
    "    if chorpus:\n",
    "        answer = index.query(question, llm=llm)\n",
    "    else:\n",
    "        response = requests.post(url, json=data, headers=headers)\n",
    "        answer = response.json()['choices'][0]['message']['content']\n",
    "    \n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "\n",
    "    return question, answer\n",
    "\n",
    "\n",
    "def conversation(corpus=False):\n",
    "    answer = None\n",
    "    question = None\n",
    "    while True:\n",
    "        user_input = input(\"Question (q=quit, s=save previous answer): \")\n",
    "        if user_input=='q':\n",
    "            break\n",
    "        if user_input==\"s\" and answer:\n",
    "            save_answer(question, answer)\n",
    "            answer = None\n",
    "        else:\n",
    "            question, answer = query(user_input, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b469436-1312-4529-bf48-b5208aabde87",
   "metadata": {},
   "source": [
    "### B. Running the conversation\n",
    "\n",
    "Now we will start a conversation with ClimateGPT. Some sample questions to begin:\n",
    "\n",
    "- What AI/ML methods are used for wildfire data analysis?\n",
    "- Summarize the impact of climate change on wildfires. Include the nature of damages caused by climate-related changes.\n",
    "- What are the biodiversity impacts of wildfire?\n",
    "\n",
    "After each question, you can:\n",
    "- Type a new question\n",
    "- Type \"s\" if you want to save your previous question\n",
    "- Type \"q\" to quit the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8400ea-4231-405c-90a9-2e37e68de370",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b8be5-6455-435c-b703-ee0acbcbd459",
   "metadata": {},
   "source": [
    "### C. Adding new context to ClimateGPT\n",
    "\n",
    "Now we will extend the capacity of the model by adding new documentation. We will use the following document:\n",
    "\n",
    "- [\"Strengthening and Democratizing the U.S. Artificial Intelligence Innovation Ecosystem: An Implementation Plan for a National Artificial Intelligence Research Resource\" (NAIRR-TF-Final-Report-2023.pdf)](https://www.ai.gov/wp-content/uploads/2023/01/NAIRR-TF-Final-Report-2023.pdf)\n",
    "\n",
    "In the following cell, we will load and embed our document, and index it for retrieval from our Vector Store.\n",
    "\n",
    "This cell might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c36c2-2853-4ebe-880e-3d0ea5225b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the new document to the model\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "file = '../PDF Documents/NAIRR-TF-Final-Report-2023.pdf'\n",
    "loader = PyPDFLoader(file)\n",
    "index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])\n",
    "llm = ChatOpenAI(model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b49fe-709c-46e9-8b44-5169b272444f",
   "metadata": {},
   "source": [
    "Once we have loaded our document, we can start making questions. Some questions that we can use to compare results are the following:\n",
    "\n",
    "* What task forces are recommended in the report?  \n",
    "* List the facilities that a NAIRR resource should provide with respect to (a) computing, (b) AI/ML models, and (c) data.  \n",
    "* What committees does the report refer to?  \n",
    "* What are NAIRR's goals with respect to human capital?\n",
    "\n",
    "Let's start with the first question: *What task forces are recommended in the report?* \n",
    "\n",
    "1. Run the *PRE-Context* cell and ask the question. You will notice that the model will respond to not possess any knowledge of a report.\n",
    "2. Type q to close the conversation\n",
    "3. Go to the next cell *POST*, and repeat the process. Now the model will provide an answer relying on the document.\n",
    "\n",
    "#### PRE-Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ad520-4ad2-4fb8-a67e-67dad9dbdbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE - In this cell, we will ask the question without giving any context to ClimateGPT\n",
    "conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb7323-0624-456e-88a2-167c03c968d6",
   "metadata": {},
   "source": [
    "Looking at the responses, we can confirm the model is given proper answers which are constructed taking the added document as context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dcfd89-7820-45e2-aa9a-8f896f5878bf",
   "metadata": {},
   "source": [
    "#### POST-Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da041b88-a134-4595-8d2d-8617853f6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POST - We add True to indicate the model to make use of the new document\n",
    "conversation(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
