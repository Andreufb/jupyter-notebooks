{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1da733-7d5b-4c6a-815b-344dcc627a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "import requests\n",
    "\n",
    "os.environ['HF_HOME']='/srv/starter_content/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfa3a4-ed7a-461a-a335-09cfeafc2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"eci-io/climategpt-7b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d7dbf-fc29-4cc4-a9a0-50ade36ba1b3",
   "metadata": {},
   "source": [
    "## NDP LLM Service Documentation\n",
    "\n",
    "This Python code snippet is designed to launch various components of a chat service named \"FastChat.\" Each function starts a different part of the service using the `subprocess.run` method to execute shell commands.\n",
    "\n",
    "### `run_controller()`\n",
    "\n",
    "Starts the controller for the FastChat service, responsible for managing and coordinating different parts of the service.\n",
    "\n",
    "```python\n",
    "def run_controller():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.controller\", \"--host\", \"127.0.0.1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153eb97-e79f-4592-8a49-5ce4ff1efe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_controller():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.controller\", \"--host\", \"127.0.0.1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3730d1d8-8a13-4b7c-907c-03b948f6633b",
   "metadata": {},
   "source": [
    "## `run_worker`\n",
    "Initiates a model worker for processing and generating responses based on specified models. Runs the model worker module, specifying the local host and a list of model names for processing requests. The --model-path argument should point to the directory where the models are stored.\n",
    "```python \n",
    "def run_model_worker():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.model_worker\", \"--host\", \"127.0.0.1\", \"--model-names\", \"eci-io/climategpt-7b,text-embedding-ada-002\", \"--model-path\", model])\n",
    "\n",
    "```\n",
    "### `run_api`\n",
    "\n",
    "Launches an API server that handles API requests to the FastChat service.\n",
    "Runs the API server module on the local host, acting as an interface between the service and external clients or applications.\n",
    "```python\n",
    "def run_api_server():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.openai_api_server\", \"--host\", \"127.0.0.1\"])\n",
    "```    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879fbbe-fdfc-42a4-b4ed-cbab96c2a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_worker():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.model_worker\", \"--host\", \"127.0.0.1\", \"--model-names\", \"eci-io/climategpt-7b,text-embedding-ada-002\", \"--model-path\", model])\n",
    "\n",
    "def run_api_server():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.openai_api_server\", \"--host\", \"127.0.0.1\"])\n",
    "def run_ui_server():\n",
    "    subprocess.run([\"python3\", \"-m\", \"fastchat.serve.gradio_web_server\", \"--host\", \"127.0.0.1\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a7ae9-3ab4-460c-baf2-80a0ae43a45a",
   "metadata": {},
   "source": [
    "## Starting the `run_controller` Function in a Separate Thread\n",
    "\n",
    "To enable the FastChat controller to run concurrently with the main program, the `run_controller` function is executed in a separate thread. This is achieved using Python's `threading` module, which allows for the execution of code in parallel to the main execution flow of the program.\n",
    "\n",
    "### Code Snippet:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "controller_thread = threading.Thread(target=run_controller)\n",
    "controller_thread.start()\n",
    "```\n",
    "\n",
    "### Note: please wait for the following output line:\n",
    "```\n",
    "2024-03-14 20:35:37 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:21001 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9629becb-dfcd-4262-be6c-d3606e711ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_thread = threading.Thread(target=run_controller)\n",
    "controller_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789765a-af59-4fc7-80a7-06b32114b829",
   "metadata": {},
   "source": [
    "## Starting the `run_model_worker` Function in a Separate Thread\n",
    "\n",
    "To facilitate concurrent execution of the FastChat model worker alongside the main program and potentially other service components, the `run_model_worker` function is executed in a separate thread. This concurrent execution is made possible through the use of Python's `threading` module.\n",
    "\n",
    "### Code Snippet:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "model_worker_thread = threading.Thread(target=run_model_worker)\n",
    "model_worker_thread.start()\n",
    "```\n",
    "\n",
    "\n",
    "### Note: please wait for the following output line:\n",
    "```\n",
    "2024-03-14 20:36:18 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:21002 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4eab9-b566-4230-8c5f-8fd73d6a8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_worker_thread = threading.Thread(target=run_model_worker)\n",
    "model_worker_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdd025-0d10-4b2a-94c5-a2fe681cf1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec420dc4-bfb8-4a29-b34b-1bab4a203385",
   "metadata": {},
   "source": [
    "## Running the `run_api_server` Function in a Separate Thread\n",
    "\n",
    "To ensure the API server component of the FastChat service operates concurrently with other parts of the application, the `run_api_server` function is launched in a separate thread. This concurrency is achieved with the help of Python's `threading` module, allowing multiple components to run simultaneously, improving scalability and responsiveness.\n",
    "\n",
    "### Code Snippet:\n",
    "\n",
    "```python\n",
    "import threading\n",
    "\n",
    "api_server_thread = threading.Thread(target=run_api_server)\n",
    "api_server_thread.start()\n",
    "\n",
    "### Note: please wait for the following output line:\n",
    "```\n",
    "2024-03-14 20:35:37 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d6983-f16e-417e-b648-fc918917c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_server_thread = threading.Thread(target=run_api_server)\n",
    "api_server_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc776567-50d7-4d33-aba4-818269392384",
   "metadata": {},
   "source": [
    "## Test that everything works and ready (the response should contain the list of models and other parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889395f9-a7b1-413e-b67b-8f494abd5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get('http://localhost:8000/v1/models').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f90cc-d1ff-4433-b75c-923fbd394630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
