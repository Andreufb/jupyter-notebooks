{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1b1153-d53c-426a-bd08-fcd779272f47",
   "metadata": {},
   "source": [
    "# Example of using ClimateGPT LLM with the document \n",
    "\n",
    "## \"Strengthening and Democratizing the U.S. Artificial Intelligence Innovation Ecosystem: An Implementation Plan for a National Artificial Intelligence Research Resource\" (NAIRR-TF-Final-Report-2023.pdf)\n",
    "\n",
    "#### Examples of questions:\n",
    "\n",
    "* List the facilities that a NAIRR resource should provide with respect to (a) computing, (b) AI/ML models, and (c) data.  \n",
    "* What committees does the report refer to?  \n",
    "* What are NAIRR's goals with respect to human capital?  \n",
    "* What task forces are recommended in the report?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0191bc9-8149-4316-8617-e8e4fda0b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "MODEL = 'eci-io/climategpt-7b'\n",
    "os.environ['OPENAI_API_BASE'] = 'http://fc-api-server:8000/v1'\n",
    "os.environ['OPENAI_API_KEY'] = 'EMPTY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ff451-27e7-41ac-901d-d6bfcfc3f9b2",
   "metadata": {},
   "source": [
    "### Test that LLM API is up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889395f9-a7b1-413e-b67b-8f494abd5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl  -X 'GET' 'http://fc-api-server:8000/v1/models' -H 'accept: application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9202a5-d8da-4cb1-bcff-a92c89443e70",
   "metadata": {},
   "source": [
    "### Load PDF file and set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c36c2-2853-4ebe-880e-3d0ea5225b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "file = 'NAIRR-TF-Final-Report-2023.pdf'\n",
    "loader = PyPDFLoader(file)\n",
    "index = VectorstoreIndexCreator(embedding=embedding).from_loaders([loader])\n",
    "llm = ChatOpenAI(model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb480fdb-4e1d-44cc-a414-223d22f38e03",
   "metadata": {},
   "source": [
    "### The conversation code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066f108-e7fd-4d29-b080-e8b3b654aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answer(question, answer):\n",
    "    with open('output.txt', 'a') as file:\n",
    "        file.write(question+'\\n')\n",
    "        file.write(answer+'\\n\\n')\n",
    "    \n",
    "\n",
    "def question(question):\n",
    "    answer = index.query(question, llm=llm)\n",
    "    \n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "\n",
    "    save = input(\"\\n\\nWould you like to save your answer? (y/n): \")\n",
    "    print('\\n')\n",
    "    if save=='y':\n",
    "        save_answer(question, answer)\n",
    "\n",
    "def conversation():\n",
    "    while True:\n",
    "        user_input = input(\"Question ('q' to quit): \")\n",
    "        if user_input=='q':\n",
    "            break\n",
    "        question(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b469436-1312-4529-bf48-b5208aabde87",
   "metadata": {},
   "source": [
    "### Run the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8400ea-4231-405c-90a9-2e37e68de370",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ad520-4ad2-4fb8-a67e-67dad9dbdbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
