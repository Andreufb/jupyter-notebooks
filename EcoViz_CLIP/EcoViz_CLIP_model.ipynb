{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jPvZoT6IipKb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# # Define the search term for querying Wikimedia Commons\n",
    "search_term = \"butterfly\" # for words or phrases that contain a space use %20 instead of space\n",
    "\n",
    "# Construct the base URL for the Wikimedia API request to fetch images related to the search term\n",
    "base_url = (f\"https://commons.wikimedia.org/w/api.php?action=query\"\n",
    "            f\"&generator=images&gimlimit=500\"\n",
    "            f\"&iiprop=timestamp%7Cuser%7Cuserid%7Ccomment%\"\n",
    "            f\"7Ccanonicaltitle%7Curl%7Csize%7Cdimensions%7Csha1%\"\n",
    "            f\"7Cmime%7Cthumbmime%7Cmediatype%7Cbitdepth%7extmetadata\"\n",
    "            f\"&prop=imageinfo&redirects=1&\"\n",
    "            f\"titles={search_term}\"\n",
    "            f\"&format=json\")\n",
    "\n",
    "# Append additional parameters to fetch license information\n",
    "base_url_license = base_url + \"&iiprop=extmetadata\"\n",
    "\n",
    "# Perform HTTP GET requests to fetch data from the Wikimedia Commons API\n",
    "response = requests.get(base_url)\n",
    "jsondata = response.json()\n",
    "\n",
    "response_license = requests.get(base_url_license)\n",
    "jsondata_license = response_license.json()\n",
    "\n",
    "def extract_page_data(pages):\n",
    "    \"\"\"\n",
    "    Extracts and processes image data and metadata from the Wikimedia Commons API response.\n",
    "\n",
    "    Args:\n",
    "        pages (dict): A dictionary containing the 'pages' part of the API response.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing processed data for an individual image.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for key, value in pages.items():\n",
    "        data = value.copy()\n",
    "        imageinfo_data = data['imageinfo'][0]\n",
    "        extmetadata = imageinfo_data.get('extmetadata', {})\n",
    "\n",
    "        # Flattening extmetadata for easier DataFrame creation\n",
    "        for ext_key, ext_value in extmetadata.items():\n",
    "            new_key = f\"extmetadata.{ext_key}\"\n",
    "            data[new_key] = ext_value.get('value', None)\n",
    "\n",
    "        # Update the main data dictionary with the flattened 'imageinfo' and 'extmetadata'\n",
    "        data.update(imageinfo_data)\n",
    "        del data['imageinfo'] # Remove the nested 'imageinfo' dictionary\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "# Extract data from the jsondata and jsondata_license structures\n",
    "data_list = extract_page_data(jsondata['query']['pages'])\n",
    "data_list_license = extract_page_data(jsondata_license['query']['pages'])\n",
    "\n",
    "# Convert the extracted data into DataFrames\n",
    "wiki_out = pd.DataFrame(data_list)\n",
    "wiki_license = pd.DataFrame(data_list_license)\n",
    "\n",
    "# Merging the data\n",
    "wiki_all = pd.merge(wiki_out, wiki_license, on='pageid', suffixes=('_basic', '_license'))\n",
    "\n",
    "#  Define a function to generate URLs for image licenses based on the license type\n",
    "def generate_url(license):\n",
    "    \"\"\"\n",
    "    Generates a URL for the image's license based on a given license type.\n",
    "\n",
    "    Args:\n",
    "        license (str): The license type of the image.\n",
    "\n",
    "    Returns:\n",
    "        str: A URL string pointing to the license details. Returns None if the license type is unrecognized.\n",
    "    \"\"\"\n",
    "    if not license:\n",
    "        return None\n",
    "\n",
    "    # Map for known license formats\n",
    "    license_map = {\n",
    "        'cc-by-sa-3.0': 'https://creativecommons.org/licenses/by-sa/3.0/',\n",
    "        'cc-by-sa-2.5': 'https://creativecommons.org/licenses/by-sa/2.5/',\n",
    "        'cc-by-sa-4.0': 'https://creativecommons.org/licenses/by-sa/4.0/',\n",
    "        'pd': 'https://creativecommons.org/publicdomain/mark/1.0/',\n",
    "        'cc-by-2.0': 'https://creativecommons.org/licenses/by/2.0/',\n",
    "        'cc-by-3.0': 'https://creativecommons.org/licenses/by/3.0/',\n",
    "        'cc-by-2.5': 'https://creativecommons.org/licenses/by/2.5/',\n",
    "        'cc0': 'https://creativecommons.org/publicdomain/zero/1.0/',\n",
    "        'cc-by-sa-2.0': 'https://creativecommons.org/licenses/by-sa/2.0/',\n",
    "        'cc-by-sa-1.0': 'https://creativecommons.org/licenses/by-sa/1.0/'\n",
    "    }\n",
    "\n",
    "    return license_map.get(license, None)\n",
    "\n",
    "# Generating license URLs\n",
    "wiki_all[\"license_url\"] = wiki_all[\"extmetadata.License\"].apply(generate_url)\n",
    "\n",
    "# Prepare the final DataFrame with selected columns, including image ID, file name, URL, and license information\n",
    "image_df = pd.DataFrame({\n",
    "    \"image_id\": range(1, len(wiki_all) + 1),\n",
    "    \"file_name\": wiki_all[\"url\"].apply(lambda x: urlparse(x).path.split('/')[-1]),\n",
    "    \"url\": wiki_all[\"url\"],\n",
    "    \"license_type\": wiki_all[\"extmetadata.License\"],\n",
    "    \"license_url\": wiki_all[\"license_url\"]\n",
    "})\n",
    "\n",
    "# List of accepted image formats for CLIP model\n",
    "acceptable_formats = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "# Filter image_df to only keep rows with filenames ending in one of the acceptable formats\n",
    "image_df = image_df[image_df['file_name'].str.lower().str.endswith(tuple(acceptable_formats))]\n",
    "\n",
    "#display begining of final dataframe\n",
    "image_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "lpIKx7KYHaL1",
    "outputId": "ce43d4fe-3033-4286-9e49-2204092e2375"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "base_url"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "BIfvsWwORpSp",
    "outputId": "81184255-0fc8-47e0-87af-2ef263a1876d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize the CLIP model with a specified checkpoint for zero-shot image classification\n",
    "checkpoint = \"openai/clip-vit-large-patch14\"\n",
    "detector = pipeline(model=checkpoint, task=\"zero-shot-image-classification\")\n",
    "\n",
    "# Define a list of candidate labels that the model will use to classify images\n",
    "candidate_labels = [\"butterfly\", \"caterpillar\", \"egg\", \"none\"]\n",
    "\n",
    "def get_predictions_from_url(image_url):\n",
    "    # Set a user-agent to prevent blocking by some websites\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    # Attempt to fetch the image from the URL\n",
    "    response = requests.get(image_url, headers=headers)\n",
    "    # Check if the request was successful and the content is an image\n",
    "    if response.status_code == 200 and 'image' in response.headers['Content-Type']:\n",
    "        try:\n",
    "            # Open the image and predict its category using CLIP\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            predictions = detector(image, candidate_labels=candidate_labels)\n",
    "            # Convert predictions to a dictionary for easier access\n",
    "            prediction_dict = {pred[\"label\"]: pred[\"score\"] for pred in predictions}\n",
    "            # Ensure all candidate labels are in the dictionary, even if they have a score of 0\n",
    "            for label in candidate_labels:\n",
    "                prediction_dict.setdefault(label, 0)\n",
    "        except IOError:\n",
    "            # Handle errors in opening the image\n",
    "            print(f\"Could not process image {image_url}\")\n",
    "            prediction_dict = {label: 0 for label in candidate_labels}\n",
    "    else:\n",
    "        # Handle failed requests or non-image content\n",
    "        print(f\"Failed to fetch or identify image from {image_url}\")\n",
    "        prediction_dict = {label: 0 for label in candidate_labels}\n",
    "    return prediction_dict\n",
    "\n",
    "def process_images_from_df(image_df):\n",
    "    # Initialize an empty list to hold data about each image\n",
    "    data = []\n",
    "    # Iterate over each row in the DataFrame of images\n",
    "    for index, row in image_df.iterrows():\n",
    "        print(f\"Processing image {index + 1}: {row['file_name']}\")\n",
    "        # Get prediction scores for the current image\n",
    "        prediction_scores = get_predictions_from_url(row['url'])\n",
    "        # Append a dictionary with the image name, URL, and prediction scores to the list\n",
    "        data.append({\"Image Name\": row['file_name'], \"Image URL\": row['url'], **prediction_scores})\n",
    "    # Convert the list of data into a DataFrame for further processing or analysis\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Process a subset of images (first x) from the DataFrame and get predictions\n",
    "image_predictions_df = process_images_from_df(image_df.head(10))\n",
    "\n",
    "# Save the predictions to a CSV file for easy sharing or further analysis\n",
    "image_predictions_df.to_csv('image_predictions.csv', index=False)\n",
    "print(\"Processing complete. Results saved to 'image_predictions.csv'.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSyCbPMxOkxx",
    "outputId": "676a5f0e-7c65-4f90-dec2-05e86e6b7d12"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35dlNtevGjzE",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "outputId": "044e2bfc-aa74-4a00-c41f-03ebb48eabaf"
   },
   "outputs": [],
   "source": [
    "image_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Use DataFrame.apply with axis=1 to calculate the most likely category for each row\n",
    "# We'll skip the first two columns ('Image Name' and 'Image URL') and apply idxmax on the rest\n",
    "image_predictions_df['Prediction'] = image_predictions_df.iloc[:, 2:].idxmax(axis=1)\n",
    "# Now, your DataFrame has an additional column named 'Most Likely Category'\n",
    "# which contains the name of the category with the highest score for each image\n",
    "\n",
    "# Display df verify\n",
    "image_predictions_df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "_-faQ2s1M5e2",
    "outputId": "ab9ee23f-42d0-43d8-d1ca-897bd23bd88e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def display_image_with_prediction(row):\n",
    "    \"\"\"\n",
    "    Fetches and displays an image from a URL, along with its predicted category.\n",
    "\n",
    "    Parameters:\n",
    "    - row: A row from the DataFrame, containing at least 'Image URL' and 'Prediction' fields.\n",
    "    \"\"\"\n",
    "    # Specify a User-Agent to simulate a browser request\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "\n",
    "    # Fetch the image with headers\n",
    "    response = requests.get(row['Image URL'], headers=headers)\n",
    "    try:\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        # Display the image using matplotlib\n",
    "        plt.figure(figsize=(5, 5))  # Adjust the figure size as needed\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')  # Hide the axis for a cleaner display\n",
    "        plt.title(f\"Prediction: {row['Prediction']}\")  # Show the prediction as the title\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the image: {e}\")\n",
    "\n",
    "# Iterate over each row in the DataFrame and display the image with its prediction\n",
    "for index, row in image_predictions_df.iterrows():\n",
    "    display_image_with_prediction(row)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "60jIYwNWP5KZ",
    "outputId": "d078dbce-5405-4d5b-99dd-9877589e369f"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyN2PKpPD3NMp8X9yEJ8CSCC",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
